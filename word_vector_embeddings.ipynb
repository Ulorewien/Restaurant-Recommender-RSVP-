{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yellow_flash/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yellow_flash/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_file = \"final_business_CA.gzip\"\n",
    "reviews_file = \"final_review_CA.gzip\"\n",
    "users_file = \"final_data_user_yelp.gzip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_pickle(reviews_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(reviews_df, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(review):\n",
    "    punctuation = set(string.punctuation)\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_W = stopwords.words(\"english\")\n",
    "    r = ''.join([c for c in review.lower() if (not c in punctuation)])\n",
    "    word_list = []\n",
    "    for w in r.split():\n",
    "        w = stemmer.stem(w)\n",
    "        if (w not in stop_W) and w.isalpha():\n",
    "            word_list.append(w)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169398it [02:43, 1036.66it/s]\n"
     ]
    }
   ],
   "source": [
    "review_list = []\n",
    "for _, df in tqdm(train_df.iterrows()):\n",
    "    review_list.append(text_preprocess(df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(review_list,\n",
    "                 min_count=5, # Words/items with fewer instances are discarded\n",
    "                 vector_size=10, # Model dimensionality\n",
    "                 window=3, # Window size\n",
    "                 sg=1,\n",
    "                 workers=6,\n",
    "                 epochs=5,\n",
    "                 compute_loss=True) # Skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sub', 0.9723308086395264),\n",
       " ('calzon', 0.960164487361908),\n",
       " ('hamburg', 0.9471043944358826),\n",
       " ('tristrami', 0.9453326463699341),\n",
       " ('gyro', 0.9428593516349792),\n",
       " ('burger', 0.9404435157775879),\n",
       " ('sammi', 0.9395216107368469),\n",
       " ('karma', 0.9375873804092407),\n",
       " ('firehous', 0.9361119270324707),\n",
       " ('guru', 0.9341705441474915)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word(\"pizza\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39131900.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_latest_training_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Word2Vec(review_list,\n",
    "                 min_count=5, # Words/items with fewer instances are discarded\n",
    "                 vector_size=50, # Model dimensionality\n",
    "                 window=3, # Window size\n",
    "                 sg=1,\n",
    "                 workers=6,\n",
    "                 epochs=30,\n",
    "                 compute_loss=True) # Skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70137488.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.get_latest_training_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-29235412.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "39131900.0 - 68367312.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pepperoni', 0.8807622790336609),\n",
       " ('margherita', 0.8415851593017578),\n",
       " ('calzon', 0.8408629298210144),\n",
       " ('rusti', 0.8264104723930359),\n",
       " ('giovanni', 0.8056952953338623),\n",
       " ('domino', 0.7669126391410828),\n",
       " ('patxi', 0.761646568775177),\n",
       " ('diavola', 0.7613298892974854),\n",
       " ('gino', 0.755900502204895),\n",
       " ('umbra', 0.7541335225105286)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.similar_by_word(\"pizza\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
